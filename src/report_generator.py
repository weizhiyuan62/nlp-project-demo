"""
æŠ¥å‘Šç”Ÿæˆæ¨¡å—
åŸºäºåˆ†æç»“æœå’Œå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆç»“æ„åŒ–çš„MarkdownæŠ¥å‘Š
"""

import logging
from typing import Dict, Any, List
from datetime import datetime
from pathlib import Path


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, config_manager):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config_manager
        self.logger = logging.getLogger(f"æ™ºè§ˆç³»ç»Ÿv{config_manager.version}")
        self.output_dir = config_manager.get_output_dir()
        self.report_style = config_manager.get_report_style()
        self.sections = config_manager.get_report_sections()
    
    def generate_report(self, 
                       topics: List[str],
                       analysis_result: Dict[str, Any],
                       visualization_paths: Dict[str, str]) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„MarkdownæŠ¥å‘Š
        
        Args:
            topics: ä¸»é¢˜åˆ—è¡¨
            analysis_result: åˆ†æç»“æœ
            visualization_paths: å¯è§†åŒ–å›¾è¡¨è·¯å¾„å­—å…¸
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        self.logger.info("å¼€å§‹ç”ŸæˆæŠ¥å‘Š...")
        
        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_content = []
        
        # æ ‡é¢˜å’Œå…ƒæ•°æ®
        report_content.append(self._generate_header(topics, analysis_result))
        
        # markdown TOC add
        report_content.append('[TOC]\n')
        
        # å„ä¸ªç« èŠ‚
        for section in self.sections:
            if section == 'executive_summary':
                report_content.append(self._generate_executive_summary(analysis_result))
            elif section == 'key_events':
                report_content.append(self._generate_key_events(analysis_result))
            elif section == 'overall_analysis':
                report_content.append(self._generate_overall_analysis(analysis_result, topics))
            elif section == 'trend_analysis':
                report_content.append(self._generate_trend_analysis(analysis_result))
            elif section == 'statistics':
                report_content.append(self._generate_statistics(analysis_result, visualization_paths))
            elif section == 'recommendations':
                report_content.append(self._generate_recommendations(analysis_result))
        
        # é™„å½•
        report_content.append(self._generate_appendix(analysis_result))
        
        # åˆå¹¶å†…å®¹
        full_report = '\n\n'.join(report_content)
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f"report_{timestamp}.md"
        report_path = self.output_dir / report_filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(full_report)
        
        self.logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
    
    def _generate_header(self, topics: List[str], analysis_result: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        statistics = analysis_result.get('statistics', {})
        topic_str = ' | '.join(topics)
        gen_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        style_name = self._get_style_name()
        total_count = statistics.get('total_count', 0)
        avg_score = statistics.get('average_score', 0)
        
        header = f"""# æ™ºè§ˆä¿¡æ¯åˆ†ææŠ¥å‘Š

> **ä¸»é¢˜**: {topic_str}

| é¡¹ç›® | å†…å®¹ |
|:-----|:-----|
| ç”Ÿæˆæ—¶é—´ | {gen_time} |
| æŠ¥å‘Šé£æ ¼ | {style_name} |
| åˆ†ææ•°é‡ | {total_count} æ¡é«˜è´¨é‡ä¿¡æ¯ |
| å¹³å‡è¯„åˆ† | {avg_score:.2f} / 1.0 |

---
"""
        return header
    
    def _generate_executive_summary(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        key_points = analysis_result.get('key_points', [])
        statistics = analysis_result.get('statistics', {})
        
        total_count = statistics.get('total_count', 0)
        source_count = len(statistics.get('source_distribution', {}))
        date_count = len(statistics.get('date_distribution', {}))
        avg_score = statistics.get('average_score', 0)
        
        summary = """## ä¸€ã€æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘ŠåŸºäºå¤šæºä¿¡æ¯é‡‡é›†å’Œæ™ºèƒ½åˆ†æï¼Œå¯¹å½“å‰å…³æ³¨ä¸»é¢˜è¿›è¡Œäº†å…¨é¢æ¢³ç†ã€‚é€šè¿‡å¤§è¯­è¨€æ¨¡å‹çš„æ·±åº¦åˆ†æï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºä»¥ä¸‹æ ¸å¿ƒè¦ç‚¹ï¼š

"""
        
        # å…³é”®è¦ç‚¹åˆ—è¡¨
        if key_points:
            for i, point in enumerate(key_points, 1):
                summary += f"{i}. {point}\n"
        else:
            summary += "*æš‚æ— å…³é”®è¦ç‚¹æå–ã€‚*\n"
        
        # ä¿¡æ¯æ¦‚è§ˆè¡¨æ ¼
        summary += f"""
### ä¿¡æ¯æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|:-----|-----:|
| é«˜è´¨é‡ä¿¡æ¯æ•° | {total_count} æ¡ |
| ä¿¡æ¯æºæ•°é‡ | {source_count} ä¸ª |
| æ—¶é—´è·¨åº¦ | {date_count} å¤© |
| å¹³å‡è´¨é‡è¯„åˆ† | {avg_score:.2f} / 1.0 |
"""
        
        return summary
    
    def _generate_key_events(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆé‡ç‚¹äº‹ä»¶è§£è¯»"""
        filtered_items = analysis_result.get('filtered_items', [])
        
        # é€‰å–è¯„åˆ†æœ€é«˜çš„å‰10æ¡
        top_items = sorted(filtered_items, key=lambda x: x.get('score', 0), reverse=True)[:10]
        
        events = """## äºŒã€é‡ç‚¹äº‹ä»¶è§£è¯»

ä»¥ä¸‹æ˜¯ç»è¿‡æ™ºèƒ½è¯„åˆ†ç­›é€‰çš„é«˜è´¨é‡ä¿¡æ¯è¦ç‚¹ï¼š

"""
        
        for i, item in enumerate(top_items, 1):
            title = item.get('title', 'æ— æ ‡é¢˜').strip()
            snippet = item.get('snippet', '').strip()
            # æˆªå–æ‘˜è¦ï¼Œä¿è¯å®Œæ•´å¥å­
            if len(snippet) > 150:
                snippet = snippet[:150].rsplit('ã€‚', 1)[0]
                if not snippet.endswith('ã€‚'):
                    snippet += '...'
            source = item.get('source_name', 'æœªçŸ¥æ¥æº')
            score = item.get('score', 0)
            url = item.get('url', '#')
            
            events += f"""### {i}. {title}

> **è¯„åˆ†**: `{score:.2f}` &nbsp;|&nbsp; **æ¥æº**: {source}

{snippet if snippet else '*æš‚æ— æ‘˜è¦*'}

ğŸ”— [æŸ¥çœ‹åŸæ–‡]({url})

"""
        
        return events
    
    def _generate_overall_analysis(self, analysis_result: Dict[str, Any], topics: List[str]) -> str:
        """ç”Ÿæˆæ€»ä½“åˆ†æç« èŠ‚"""
        overall_analysis = analysis_result.get('overall_analysis', '')
        topic_str = 'ã€'.join(topics)
        
        section = f"""## ä¸‰ã€æ™ºè§ˆæ€»ä½“åˆ†æ

> åŸºäºä»¥ä¸Šé‡‡é›†çš„ä¿¡æ¯å’Œé‡ç‚¹äº‹ä»¶ï¼Œæ™ºè§ˆç³»ç»Ÿå¯¹ã€Œ{topic_str}ã€è¿›è¡Œçš„æ·±åº¦æ€»ä½“åˆ†æå¦‚ä¸‹ï¼š

"""
        
        if overall_analysis:
            # ç¡®ä¿ LLM è¿”å›çš„åˆ†æå†…å®¹æ ¼å¼ç»Ÿä¸€ï¼Œå°†å¯èƒ½çš„ ## æ ‡é¢˜é™çº§ä¸º ###
            formatted = overall_analysis.replace('## ', '### ').replace('# ', '### ')
            section += formatted
        else:
            section += '*æš‚æ— æ€»ä½“åˆ†ææ•°æ®ã€‚*'
        
        return section
    
    def _generate_trend_analysis(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        statistics = analysis_result.get('statistics', {})
        date_dist = statistics.get('date_distribution', {})
        
        trend = """## å››ã€è¶‹åŠ¿åˆ†æ

### 4.1 ä¿¡æ¯å‘å¸ƒè¶‹åŠ¿

"""
        
        if date_dist:
            sorted_dates = sorted(date_dist.items())
            max_date = max(sorted_dates, key=lambda x: x[1])
            min_date = min(sorted_dates, key=lambda x: x[1])
            trend_direction = 'ğŸ“ˆ ä¸Šå‡' if sorted_dates[-1][1] > sorted_dates[0][1] else 'ğŸ“‰ ä¸‹é™'
            
            trend += f"""åŸºäºæ—¶é—´åºåˆ—åˆ†æï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä»¥ä¸‹è¶‹åŠ¿ï¼š

| æŒ‡æ ‡ | æ—¥æœŸ | æ•°é‡ |
|:-----|:-----|-----:|
| å‘å¸ƒé«˜å³° | {max_date[0]} | {max_date[1]} æ¡ |
| å‘å¸ƒä½è°· | {min_date[0]} | {min_date[1]} æ¡ |

**æ€»ä½“è¶‹åŠ¿**: {trend_direction}

ä¿¡æ¯å‘å¸ƒçš„æ—¶é—´åˆ†å¸ƒåæ˜ äº†è¯¥ä¸»é¢˜åœ¨è¿‘æœŸçš„å…³æ³¨åº¦å˜åŒ–ã€‚
"""
        else:
            trend += "*æš‚æ— è¶³å¤Ÿçš„æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚*\n"
        
        trend += "\n### 4.2 ä¿¡æ¯æ¥æºåˆ†æ\n\n"
        
        source_dist = statistics.get('source_distribution', {})
        if source_dist:
            total = sum(source_dist.values())
            sorted_sources = sorted(source_dist.items(), key=lambda x: x[1], reverse=True)
            
            trend += "| æ¥æº | æ•°é‡ | å æ¯” |\n|:-----|-----:|-----:|\n"
            for source, count in sorted_sources:
                percentage = count / total * 100
                trend += f"| {source} | {count} æ¡ | {percentage:.1f}% |\n"
        else:
            trend += "*æš‚æ— ä¿¡æ¯æ¥æºæ•°æ®ã€‚*\n"
        
        return trend
    
    def _generate_statistics(self, analysis_result: Dict[str, Any], 
                            visualization_paths: Dict[str, str]) -> str:
        """ç”Ÿæˆæ•°æ®ç»Ÿè®¡ç« èŠ‚"""
        statistics_section = """## äº”ã€æ•°æ®ç»Ÿè®¡ä¸å¯è§†åŒ–

æœ¬ç« èŠ‚é€šè¿‡å¤šç»´åº¦ç»Ÿè®¡å’Œå¯è§†åŒ–å›¾è¡¨ï¼Œå‘ˆç°ä¿¡æ¯é‡‡é›†å’Œåˆ†æçš„æ•´ä½“æƒ…å†µã€‚

"""
        
        viz_items = [
            ('wordcloud', '5.1 çƒ­ç‚¹è¯äº‘å›¾', 'wordcloud.png', 
             'è¯äº‘å›¾å±•ç¤ºäº†æœ¬æ¬¡åˆ†æä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å…³é”®è¯ï¼Œè¯æ±‡å¤§å°ä»£è¡¨å…¶å‡ºç°é¢‘æ¬¡ã€‚'),
            ('timeline', '5.2 æ—¶é—´è¶‹åŠ¿å›¾', 'timeline.png', 
             'æ—¶é—´è¶‹åŠ¿å›¾å±•ç¤ºäº†ä¿¡æ¯å‘å¸ƒçš„æ—¶é—´åˆ†å¸ƒï¼Œåæ˜ ä¸»é¢˜çƒ­åº¦çš„å˜åŒ–ã€‚'),
            ('source_distribution', '5.3 ä¿¡æ¯æºåˆ†å¸ƒ', 'source_distribution.png', 
             'ä¿¡æ¯æºåˆ†å¸ƒå›¾å±•ç¤ºäº†å„æ•°æ®æºçš„è´¡çŒ®å æ¯”ã€‚'),
            ('score_distribution', '5.4 è´¨é‡è¯„åˆ†åˆ†å¸ƒ', 'score_distribution.png', 
             'è´¨é‡è¯„åˆ†åˆ†å¸ƒå›¾å±•ç¤ºäº†ç­›é€‰åä¿¡æ¯çš„è´¨é‡åˆ†å¸ƒæƒ…å†µã€‚'),
        ]
        
        has_viz = False
        for key, title, filename, desc in viz_items:
            if key in visualization_paths:
                has_viz = True
                statistics_section += f"""### {title}

<div align="center">

![{title}](./assets/{filename})

</div>

{desc}

"""
        
        if not has_viz:
            statistics_section += "*æš‚æ— å¯è§†åŒ–å›¾è¡¨ã€‚*\n"
        
        return statistics_section
    
    def _generate_recommendations(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆå»ºè®®ç« èŠ‚"""
        statistics = analysis_result.get('statistics', {})
        avg_score = statistics.get('average_score', 0)
        
        # æ ¹æ®å¹³å‡åˆ†ç»™å‡ºä¸åŒå»ºè®®
        quality_note = 'æ•´ä½“è´¨é‡è¾ƒé«˜' if avg_score >= 0.7 else 'å»ºè®®æ‰©å¤§é‡‡é›†èŒƒå›´ä»¥è·å–æ›´å¤šé«˜è´¨é‡ä¿¡æ¯'
        
        recommendations = f"""## å…­ã€ç›¸å…³å»ºè®®

åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬æå‡ºä»¥ä¸‹å»ºè®®ï¼š

### 6.1 å…³æ³¨è¦ç‚¹

| åºå· | å»ºè®® | è¯´æ˜ |
|:----:|:-----|:-----|
| 1 | **æŒç»­ç›‘æµ‹** | æŒç»­å…³æ³¨é«˜è¯„åˆ†ä¿¡æ¯æºï¼ŒåŠæ—¶è·å–æœ€æ–°åŠ¨æ€ |
| 2 | **æ·±åº¦åˆ†æ** | å¯¹é‡ç‚¹äº‹ä»¶è¿›è¡Œæ›´æ·±å…¥çš„è°ƒç ”å’Œåˆ†æ |
| 3 | **è¶‹åŠ¿é¢„åˆ¤** | ç»“åˆå†å²æ•°æ®å’Œå½“å‰è¶‹åŠ¿ï¼Œé¢„åˆ¤æœªæ¥å‘å±•æ–¹å‘ |

### 6.2 ä¿¡æ¯è´¨é‡

- æœ¬æ¬¡åˆ†æçš„ä¿¡æ¯ç»è¿‡å¤šç»´åº¦è¯„åˆ†ç­›é€‰ï¼Œ{quality_note}
- å»ºè®®é‡ç‚¹å…³æ³¨è¯„åˆ†åœ¨ **0.8 ä»¥ä¸Š** çš„ä¿¡æ¯
- å¯¹äºæ¥æºå•ä¸€çš„ä¿¡æ¯ï¼Œå»ºè®®è¿›è¡Œäº¤å‰éªŒè¯

### 6.3 åç»­è¡ŒåŠ¨

1. é’ˆå¯¹é‡ç‚¹äº‹ä»¶åˆ¶å®šåº”å¯¹ç­–ç•¥
2. å®šæœŸæ›´æ–°åˆ†ææŠ¥å‘Šï¼ŒæŠŠæ¡æœ€æ–°åŠ¨æ€
3. å»ºç«‹ä¿¡æ¯ç›‘æµ‹æœºåˆ¶ï¼Œç¡®ä¿ä¸é—æ¼é‡è¦ä¿¡æ¯
"""
        
        return recommendations
    
    def _generate_appendix(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆé™„å½•"""
        gen_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        appendix = f"""---

## é™„å½•

### A. åˆ†ææ–¹æ³•è¯´æ˜

æœ¬æŠ¥å‘Šé‡‡ç”¨ **æ™ºè§ˆ** æ™ºèƒ½ä¿¡æ¯èšåˆä¸åˆ†æç³»ç»Ÿç”Ÿæˆï¼Œè¯¥ç³»ç»Ÿå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

| ç‰¹ç‚¹ | è¯´æ˜ |
|:-----|:-----|
| å¤šæºé‡‡é›† | æ•´åˆ Google Search (SerpAPI)ã€NewsAPIã€arXiv ç­‰å¤šä¸ªæ•°æ®æº |
| æ™ºèƒ½ç­›é€‰ | ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šç»´åº¦è¯„åˆ†ï¼ˆç›¸å…³æ€§ã€é‡è¦æ€§ã€æ—¶æ•ˆæ€§ã€å¯é æ€§ï¼‰ |
| æ·±åº¦åˆ†æ | æå–å…³é”®è¦ç‚¹ï¼Œè¯†åˆ«ä¿¡æ¯å…³è”å…³ç³» |
| å¯è§†åŒ–å‘ˆç° | ç”Ÿæˆè¯äº‘ã€è¶‹åŠ¿å›¾ç­‰å¤šç§å¯è§†åŒ–å›¾è¡¨ |
| è‡ªåŠ¨åŒ–æµç¨‹ | å…¨æµç¨‹è‡ªåŠ¨åŒ–ï¼Œæ”¯æŒå®šæœŸæ›´æ–° |

### B. è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | æƒé‡ | è¯´æ˜ |
|:-----|:----:|:-----|
| ç›¸å…³æ€§ (relevance) | 30% | è¡¡é‡ä¿¡æ¯ä¸ä¸»é¢˜çš„å…³è”ç¨‹åº¦ |
| é‡è¦æ€§ (importance) | 30% | è¡¡é‡ä¿¡æ¯çš„é‡è¦æ€§å’Œå½±å“åŠ› |
| æ—¶æ•ˆæ€§ (timeliness) | 20% | è¡¡é‡ä¿¡æ¯çš„æ–°é²œåº¦ |
| å¯é æ€§ (reliability) | 20% | è¡¡é‡ä¿¡æ¯æ¥æºçš„æƒå¨æ€§ |

**ç»¼åˆè¯„åˆ†å…¬å¼**: `score = 0.3Ã—relevance + 0.3Ã—importance + 0.2Ã—timeliness + 0.2Ã—reliability`

### C. æŠ€æœ¯æ ˆ

| æ¨¡å— | æŠ€æœ¯ |
|:-----|:-----|
| æ•°æ®é‡‡é›† | Requests, SerpAPI, BeautifulSoup |
| æ™ºèƒ½åˆ†æ | å¤§è¯­è¨€æ¨¡å‹ API (Qwen / GPT) |
| æ•°æ®å¯è§†åŒ– | Matplotlib, Seaborn, WordCloud |
| æ–‡æœ¬å¤„ç† | Jieba, NLTK |
| æŠ¥å‘Šç”Ÿæˆ | Markdown, LaTeX |

---

<div align="center">

*æœ¬æŠ¥å‘Šç”±æ™ºè§ˆç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆäº {gen_time}*

</div>
"""
        
        return appendix
    
    def _get_style_name(self) -> str:
        """è·å–æŠ¥å‘Šé£æ ¼åç§°"""
        style_names = {
            'brief': 'ç®€æ˜æ–°é—»é£æ ¼',
            'detailed': 'æ·±åº¦åˆ†æé£æ ¼',
            'academic': 'å­¦æœ¯åˆŠç‰©é£æ ¼'
        }
        return style_names.get(self.report_style, self.report_style)


if __name__ == "__main__":
    # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨
    from config import get_config
    from logger import LoggerManager
    
    config = get_config()
    log_manager = LoggerManager(config)
    generator = ReportGenerator(config, log_manager)
    
    # æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
    test_analysis = {
        'filtered_items': [
            {
                'title': 'GPT-4å‘å¸ƒé‡å¤§æ›´æ–°',
                'snippet': 'äººå·¥æ™ºèƒ½é¢†åŸŸè¿æ¥æ–°çªç ´',
                'source_name': 'TechCrunch',
                'score': 0.9,
                'url': 'https://example.com'
            }
        ],
        'key_points': ['è¦ç‚¹1', 'è¦ç‚¹2'],
        'statistics': {
            'total_count': 35,
            'average_score': 0.75,
            'source_distribution': {'NewsAPI': 15, 'Google (SerpAPI)': 12, 'arXiv': 8},
            'date_distribution': {'2025-12-21': 8, '2025-12-22': 12, '2025-12-23': 15}
        }
    }
    
    test_viz_paths = {
        'wordcloud': 'assets/wordcloud.png',
        'timeline': 'assets/timeline.png'
    }
    
    report_path = generator.generate_report(['Test Case: è‡ªç„¶è¯­è¨€å¤„ç†'], test_analysis, test_viz_paths)
    print(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
